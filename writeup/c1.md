# Writing a C Compiler in Zig - chapter one

In a constant drive to spend, or waste, time while I am looking for work, I got and worked through Nora Sandler's [Writing a C Compiler](https://norasandler.com/2022/03/29/Write-a-C-Compiler-the-Book.html) in [Rust](https://github.com/asibahi/trjm). It is an excellent introduction to things like immediate representation and `z86_64` assembly. About halfway through the book, however, I lost focus.

Continuing to have nothing particularly productive to do, I figured that I could try following the book again in a different language: either Swift or Zig. I do want to learn Swift eventually as writing Apps is probably more useful than writing operating systems, but the tooling leaves something to be desired. So Zig it is, for the time being.

[Zig](https://ziglang.org) is a very opinionated "C replacement". It has a lot of weird and arbitrary design decisions: no typed integer literals (`@as(u8, 1)` instead of `1u8`) for example. But it also has a lot of nice ideas and it is being posited as the hottest thing since sliced bread, so why not Zig. Swift can happen later.

Zig, and the [Zig Version Manager](https://github.com/tristanisham/zvm) were already on my machine from previous flirtations with the language. `0.14.0` is the latest zig "release", so that is what I am using.

I decided to call this project `paella`. I like paella. So without further ado, let's go.

## `build.zig`

Zig is not being marketed, as it were, as a language. It is being marketed as a build system that just happens to have a language attached. `zig init` in the terminal creates a template project with full explanations of the basic building blocks.

Editing it to what I need, this is where I landed:

```zig
// build.zig
const std = @import("std");
pub fn build(b: *std.Build) void {

    // entry point
    const exe_mod = b.createModule(.{
        .root_source_file = b.path("src/main.zig"),

        // this is the target for the Book and my machine.
        .target = b.resolveTargetQuery(.{
            .cpu_arch = .x86_64,
            .os_tag = .macos,
        }),

        // choose optimization based on --release
        .optimize = switch (b.release_mode) {
            .off => .Debug,
            else => .ReleaseFast,
        }
    });

    const exe = b.addExecutable(.{
        .name = "paella",
        .root_module = exe_mod,
    });
    b.installArtifact(exe);

    // the rest is boiler plate for `zig build run` and `zig build test`
    // ...
}
```

I did not include all the boiler plate that would allow me to, use `zig build run` instead of `zig run main src/main.zig`. Not much better, just nicer. Also a build system currently would let me add dependecnies easier later.

`build.zig.zon` is whatever the initial command spit up, tbh. But it is where dependencies are to be listed later on.

The test suite and the book expect everything to use the `x86_64` CPU architecture, which is a little inconvenient in macOS due to it being on `aarm64`. This is howver well explained in the book and the environemnt set up for it is already done when doing the Book previously in Rust.

## The Compiler Driver

The next step is what is called in the book the Compiler Driver, or rather the framework which surrounds the compiler bits the Book is axctually about.

The Driver does several things:

1. Takes a file path and an optional phase flag as arguments.
2. Calls the system's compiler, `gcc` to preprocess the C source file at said path, (so no macros or comments or compiler flags or whatever),
3. Calls the to-be-implemented compiler to transform the preproccessed file on disk into assembly, or stop at the requested compilation phase.
4. And finally, calls `gcc` againt to assemble the assembly file into machine code.

The reason I am actually spelling it out, even though it is spelt out in the Book, is that it got me really confused at first. I thought the Driver was a separate thing that we will get to later. But no, it was pretty much step zero.

### Argument Parsing

The simple argument parsing needed doesnt warrant getting a whole library in. The program will be called by the test suite and is not really meant for public consumption. So the bare mimimum it is. (The returned errors are for my benenfit.)

```zig
const Args = struct {
    path: [:0]const u8, // a string in zigland
    mode: Mode,
};
pub const Mode = enum { lex, parse, codegen, compile, assembly };

fn parse_args() !Args {
    var args = std.process.args();
    _ = args.skip();
    const path = args.next() orelse
        return error.PathNotFound;

    const mode: Mode = if (args.next()) |arg|
        std.meta.stringToEnum(Mode, arg[2..]) orelse
            return error.UnrecognizedFlag
    else
        .compile;

    return .{ .path = path, .mode = mode };
}
```

This code snippet makes use of some of the higher level Zig features, including two ways to unwrap optional values.

```zig
const optional_int: ?i32 = 5; // ?i32 is an optional i32

// first one
const If_is_an_expression: i32 = if (optional_int) |int|
    // `int` is in scope here and we can do things
    int
else
    7;

// second onw
// unwraps the result or returns a value.
const definite_int: i32 = optional_int orelse 7;

// the two are exactly the same.
```

### Calling Commands

To run the preprocessor before compiling and the assembler after compiling, one needs to make use of `std.process.Child`.

The quickest and least painful way to do so is `Child.run()`. However, this by default allocates, and returns, `stdout` and `stderr`. If the intent is to forward them to the parent process (which it is), the easiest way is this:

```zig
var child = std.process.Child.init(
    &.{ "echo", "something" },
    allocator, // zig is all about passing allocators
);
// change options of `child` here: for example
// child.stdout_behavior = .Ignore;

// term is the retruned result of said process.
const term = try child.spawnAndWait();
```

### Manipulating File Extensions

However, before that, let's get started at the much more complex problem of changing a file's extension.[^estension] Zig's standard library provides a few ways to get the components, as it were, from a file path. They live in the `std.fs.path` and `std.mem` namespacez. After a bunch of trails and errors, I came up with the folliwng.

[^extension]: Rust provides a nice, encapsulated, function for this: [`with_extension`](https://doc.rust-lang.org/std/path/struct.Path.html#method.with_extension). But this is Zig: why have a convenient function for a common operation when one can instead do things the complicated and explicit way? Explicitness is extremely important, you know.

```zig
const path = "foo/bar.txt";
const stem = try std.fs.path.join(
    alloc,
    &.{
        std.fs.path.dirname(path) orelse "",
        std.fs.path.stem(path),
    },
);
defer alloc.free(stem);

const new_path = try std.mem.join(
    alloc,
    ".",
    &.{
        stem,
        "TXT",
    },
);
defer alloc.free(new_path);
std.debug.assert(std.mem.eql(u8, new_path, "foo/bar.TXT"));
```

### Finally!(?)

Putting two and two together, this is the first draft of the compiler driver. I am not even sure if it compiles or if I made any dumb mistakes, because the hole in the middle is rather large and it needs filling first.

```zig
const std = @import("std");

pub fn main() !void {
    var debug_allocator = std.heap.DebugAllocator(.{}).init;
    defer _ = debug_allocator.deinit(); // leak detection in Debug

    const gpa = debug_allocator.allocator();

    const args = try parse_args();
    try run(gpa, args);
}

pub fn run(
    alloc: std.mem.Allocator,
    args: Args,
) !void {
    const input_path = args.path;
    const pp_out, const asm_out, const exe =
        try get_output_paths(alloc, input_path);
    defer { // yay for manual memory management
        alloc.free(pp_out);
        alloc.free(asm_out);
        alloc.free(exe);
    }

    { // preprocessor
        var child = std.process.Child.init(
            &.{ "gcc", "-E", "-P", input_path, "-o", pp_out },
            alloc,
        );

        const term = try child.spawnAndWait();
        if (!std.meta.eql(term, .{ .Exited = 0 }))
            return error.PreprocessorFail;
    }

    { // compiler
        _ = args.mode;
        // mode controls compilation here

        // todo
        // take from path `pp_out` output to path `asm_out`
    }

    { // assembler
        var child = std.process.Child.init(
            &.{ "gcc", asm_out, "-o", exe },
            alloc,
        );

        try std.fs.cwd().deleteFile(asm_out); // cleanup

        const term = try child.spawnAndWait();
        if (!std.meta.eql(term, .{ .Exited = 0 }))
            return error.AssemblerFail;
    }
}

pub const Args = struct {
    path: [:0]const u8,
    mode: Mode,
};
pub const Mode = enum {
    lex,
    parse,
    codegen,
    compile, // default
    assembly, // unused by test script - useful for debugging
};

pub fn parse_args() !Args {
    var args = std.process.args();
    _ = args.skip();
    const path = args.next() orelse
        return error.PathNotFound;

    const mode: Mode = if (args.next()) |arg|
        std.meta.stringToEnum(Mode, arg[2..]) orelse
            return error.UnrecognizedFlag
    else
        .compile;

    return .{ .path = path, .mode = mode };
}

fn get_output_paths(
    alloc: std.mem.Allocator,
    input_path: []const u8,
) !struct {
    []const u8,
    []const u8,
    []const u8,
} {
    const exe = try std.fs.path.join(
        alloc,
        &.{
            std.fs.path.dirname(input_path) orelse "",
            std.fs.path.stem(input_path),
        },
    );
    errdefer alloc.free(exe);

    const pp = try std.mem.join(
        alloc,
        ".",
        &.{ exe, "i" },
    );
    errdefer alloc.free(pp);

    // keywords and arbitrary strings become idenitfiers in zig like so
    const @"asm" = try std.mem.join(
        alloc,
        ".",
        &.{ exe, "s" },
    );

    return .{ pp, @"asm", exe };
}
```

## Lexer

The Book takes things *very* gradually. So in the first chapter it just focuses on build the bare minimum of the compiler. The C program to be compiled in that chapter is this:

```c
int main (void) {
    return 0;
}
```

No, seriously, that's it. And the preprocessor takes care of pesky things like comments. The lexer is absurdly simple, for now.

In Ruat, I did all the lexing ahd parsing with `nom`, the lovely parser combinator library. However, here things should be done the old-fashioned, imperative way. That's why the `0.14.0` Zig release instroduced a new feature: labelled `switch`![^switch]

[^switch]: Which is really just a loop in switch clothing.

```zig
const State = enum { a, b, c, d };

loop: switch (State.a) {
    .a => {
        std.debug.print("reached .a\n", .{});
        // fallthrough at home
        continue :loop .b;
    },
    .b => {
        std.debug.print("reached .b\n", .{});
        if (today == .monday)
            continue :loop .c
        else
            continue :loop .d;
    },
    .c => std.debug.print("reached .c\n", .{}),
    .d => std.debug.print("reached .d\n", .{}),
}
```

The biggest, clearest example of using it is in the [Zig compiler itself](https://github.com/ziglang/zig/blob/master/lib/std/zig/tokenizer.zig). It is a cool design so I decided to just copy the design as is.[^unicode].

[^unicode]: An interesting tidbit: the Zig lexer/tokenizer only supports the ASCII letters for identifiers. If one wnats to use Unicode, it should be escaped like keywords do inside `@""`. This has the benefit of the Unicode data not being a dependency of the compiler, and it simplifies lexing.

There are a few moving parts, so I added a bunch of comments to explain.

```zig
// lexer.zig
const std = @import("std");

// each Token carries a tag and a span (called `loc` here.)
pub const Token = struct {
    tag: Tag,
    loc: Loc,

    // location within the source file
    pub const Loc = struct {
        start: usize,
        end: usize,
    };

    // keywords identified here with their corresponding tags.
    pub const keywords = std.StaticStringMap(Tag).initComptime(.{
        .{ "return", .keyword_return },
        .{ "int", .type_int },
        .{ "void", .keyword_void },
        .{ "main", .keyword_main },
    });

    // helper function for the above
    pub fn getKeyword(bytes: []const u8) ?Tag {
        return keywords.get(bytes);
    }

    // the tag collection
    pub const Tag = enum {
        // punctuation
        l_paren,
        r_paren,
        l_brace,
        r_brace,
        semicolon,

        number_literal,

        // keywords
        type_int,
        keyword_void,
        keyword_return,
        keyword_main, // identifiers happen later

        // helpers
        identifier, // useful for state for now
        invalid,

        // this and the one below it are unused for now, but maybe useful later?
        pub fn lexeme(tag: Tag) ?[]const u8 {
            return switch (tag) {
                .invalid,
                .number_literal,
                .identifier,
                => null,

                .l_paren => "(",
                .r_paren => ")",
                .l_brace => "{",
                .r_brace => "}",

                .semicolon => ";",

                .type_int => "int",
                .keyword_void => "void",
                .keyword_return => "return",
                .keyword_main => "main",
            };
        }

        pub fn symbol(tag: Tag) []const u8 {
            return tag.lexeme() orelse switch (tag) {
                .invalid => "invalid token",
                .identifier => "an identifier",
                .number_literal => "a number literal",
                else => unreachable,
            };
        }
    };
};

// the lexer state machine
pub const Tokenizer = struct {
    // pointer to source
    buffer: [:0]const u8,

    // where in source we are
    index: usize = 0,

    pub fn init(buffer: [:0]const u8) Tokenizer {
        return .{ .buffer = buffer };
    }

    // states. this will grow in complexity with more tokens.
    const State = enum {
        start,
        identifier,
        int,
    };

    // the loop itself
    pub fn next(self: *Tokenizer) ?Token {
        // the eventually returned value.
        var result: Token = .{
            .tag = undefined,
            .loc = .{
                .start = self.index,
                .end = undefined,
            },
        };
        state: switch (State.start) {
            // the starting state for every new token.
            .start => switch (self.buffer[self.index]) {
                0 => { // nullbyte
                    if (self.index == self.buffer.len) {
                        return null; // eof
                    } else {
                        result.tag = .invalid;
                    }
                },
                ' ', '\n', '\t', '\r' => { // whitespace
                    self.index += 1; // advance cursor
                    result.loc.start = self.index;
                    continue :state .start; // and restart
                },
                'a'...'z', 'A'...'Z', '_' => {
                    result.tag = .identifier;
                    continue :state .identifier; // move to identifier state
                },
                '0'...'9' => {
                    result.tag = .number_literal;
                    self.index += 1;
                    continue :state .int; // move to integer state
                },
                // all of the following is self-explanatory really
                '(' => {
                    result.tag = .l_paren;
                    self.index += 1;
                },
                ')' => {
                    result.tag = .r_paren;
                    self.index += 1;
                },
                ';' => {
                    result.tag = .semicolon;
                    self.index += 1;
                },
                '{' => {
                    result.tag = .l_brace;
                    self.index += 1;
                },
                '}' => {
                    result.tag = .r_brace;
                    self.index += 1;
                },
                else => result.tag = .invalid,
            },

            .identifier => {
                self.index += 1;
                switch (self.buffer[self.index]) {
                    // keep going until ...
                    'a'...'z', 'A'...'Z', '_', '0'...'9' => continue :state .identifier,
                    // .. something other than those happens
                    else => {
                        const ident = self.buffer[result.loc.start..self.index];

                        // check if it s a keyword
                        if (Token.getKeyword(ident)) |tag| {
                            result.tag = tag;
                        }
                    },
                }
            },

            .int => switch (self.buffer[self.index]) {
                '0'...'9' => {
                    self.index += 1;
                    continue :state .int;
                },
                // integers not allowed to have letters after them, for now.
                'a'...'z', 'A'...'Z' => result.tag = .invalid,
                else => {},
            },
        }

        // tidy up.
        result.loc.end = self.index;
        return result;
    }
};
```

It is a bit cut down from the original behemoth, but this will grow in complexity as I advance through the book. The corresponding file in my Rust implementation eventually became full of macros and slowed rust-analyzer to a crawl.

The stub in `main.zig` is filled as follows:

```zig
// main.zig
{ // compiler
    // the use of the more complex function here is to specify the sentinel null terminator ...
    const src = try std.fs.cwd().readFileAllocOptions(
        alloc,
        pp_out,
        std.math.maxInt(usize),
        null,
        @alignOf(u8),
        0, // .. this null terminator.here. The rest are defaults.
    );
    try std.fs.cwd().deleteFile(pp_out); // cleanup
    defer alloc.free(src);

    var tokenizer = lexer.Tokenizer.init(src);
    while (tokenizer.next()) |token| {
        // just to see the results for now.
        std.debug.print("{?}: {s}\n", .{
            token.tag,
            src[token.loc.start..token.loc.end],
        });

        switch (token.tag) {
            .invalid => return error.LexFail,
            else => {},
        }
    }

    if (args.mode == .lex) return;

    // to be continued
}
```

Unlike the original implementation, there are a few differences: it does not attempt to recover on new lines, but breaks as soon as one invalid token happens. This is actually a terrible idea but it is passable in a toy compiler. Also there is no `eof` token, choosing to return `null` on source file end. Not very data oriented of me, as it increases the size by a byte (probably), but I will live.

Bugs shall be found when I tie it to the book's test suite.

## Setting Up Tests

This is actually so dumb it is not worth its own section. Just clone the book's tests repo and create a symlink to the compiler in the base directory. For futre reference, this is what I typed to create said symlink:

```sh
# while in the tests folder
ln -s ../paella/zig-out/bin/paella
```

Then I just call the tests as follows from the same said folfer.

```sh
./test_compiler ./paella --chaoter 1 --stage lex
```

All tests should pass now.

```
Ran 24 tests in 2.008s

FAILED (failures=19)
```

Oh come on.

All of these errors seem to be hitting the `error.UnrecognizedFlag` specified in the argument parser. Debugging the situation, with friendly `std.debug.print`, showed me that not all calls to the function have the same order of arguments, which is definitely a surprise. The argument parsing code clearly needs to be revised.

```zig
pub fn parse_args() !Args {
    var args = std.process.args();
    _ = args.skip();

    var path: ?[:0]const u8 = null;
    var mode: Mode = .compile;

    while (args.next()) |arg| {
        if (arg[0] == '-') {
            mode = std.meta.stringToEnum(Mode, arg[2..]) orelse
                return error.UnrecognizedFlag;
        } else if (path == null) {
            path = arg;
        } else {
            return error.PathDeplicated;
        }
    }

    return .{
        .path = path orelse return error.PathNotFound,
        .mode = mode,
    };
}
```

Let's try again.

```
----------------------------------------------------------------------
Ran 24 tests in 2.420s

OK
```

Yay.
