# Writing a C Compiler - Chapter 9 - in Zig

<!-- Done Date: 2025-05-27 -->

After [eight](c8.md) grueling (not really) chapters of [Writing a C Compiler](https://norasandler.com/2022/03/29/Write-a-C-Compiler-the-Book.html), time to implement more assembly instructions. Functions! Linkage! Commas!

---

## Lexer, AST, and Parser

Lexer just has a comma now. I thought about adding the comma operator but that didnt seem worth the trouble.

The AST has two new additions. Function call expressions and function declarations (which are rebranded and improved function definitons)! Other changes include how the structures themselves are defined. A program is now a _list_ of function delcarations, instead of just one. How about that?

These are the new AST nodes. I am not sure these compile or not yet, which I will find out when I am done with the parser. The use of `SegmentedList` is discussed a couple of chapters ago as a more Arena-friendly collection type.

```zig
pub const Prgm = struct {
    funcs: std.SegmentedList(FuncDecl, 0),
};

pub const Block = struct {
    body: std.SegmentedList(BlockItem, 0),
};

pub const BlockItem = union(enum) {
    D: Decl,
    S: Stmt,
};

pub const Decl = union(enum) {
    F: FuncDecl,
    V: VarDecl,
};

pub const FuncDecl = struct {
    name: []const u8,
    params: std.SegmentedList(Identifier, 0),
    block: ?Block,
};

pub const VarDecl = struct {
    name: Identifier,
    init: ?*Expr,
};

pub const Expr = union(enum) {
    // snip --
    func_call: struct { Identifier, std.SegmentedList(Expr, 0) },
};

// This was implemented last chapter fixing the Segmentation Fault!
pub const Identifier = union(enum) {
    name: []const u8,
    idx: utils.StringInterner.Idx,
};
```

It is going to be annoying fixing all the type errors throughout. Nonethelesss the parsing grammar for these new node types are going to change significantly. Here is. This is the new, tentative, `parse_prgm`. I am not sure this is entirely correct yet.

```zig
pub fn parse_prgm(
    arena: std.mem.Allocator,
    tokens: *lexer.Tokenizer,
) Error!ast.Prgm {
    var funcs: std.SegmentedList(ast.FuncDecl, 0) = .{};

    while (tokens.next()) |next_token| {
        tokens.put_back(next_token);
        const func_decl = try parse_func_decl(arena, tokens);
        try funcs.append(arena, func_decl);
    }

    return .{ .funcs = funcs };
}
```

`parse_func_decl` is the same as the old `parse_func_def`, but with optional parameters and an optional body. Ok maybe not the same, it is a behemoth. And all this is going to get siginficantly more complex when adding different types than `int`.

```zig
fn parse_func_decl(
    arena: std.mem.Allocator,
    tokens: *lexer.Tokenizer,
) Error!ast.FuncDecl {
    // same old
    try expect(.type_int, tokens);
    const name = try expect(.identifier, tokens);

    // new stuff !!
    var params: std.SegmentedList(ast.Identifier, 0) = .{};
    { // params
        try expect(.l_paren, tokens);
        const next_token = tokens.next() orelse
            return error.SyntaxError;
        // labelled switch to loop over mutliple paramters.
        params: switch (next_token.tag) {
            // old bahaviour is this:
            .keyword_void => try expect(.r_paren, tokens),

            // new optional paramters
            .type_int => {
                const ident = try expect(.identifier, tokens);
                try params.append(arena, .{ .name = ident });
                const next_next = tokens.next() orelse
                    return error.SyntaxError;

                // loops back here. this would be sginifcantly more annoying
                // to write without labeled switch
                switch (next_next.tag) {
                    .comma => {
                        try expect(.type_int, tokens);
                        continue :params .type_int;
                    },
                    .r_paren => {},

                    // could just retunr here but where is the fun then?
                    else => continue :params .invalid,
                }
            },
            else => return error.SyntaxError,
        }
    }
    const block = block: {
        const peeked = tokens.next() orelse
            return error.SyntaxError;

        switch (peeked.tag) {
            .semicolon => break :block null,
            .l_brace => {
                tokens.put_back(peeked);
                break :block try parse_block(arena, tokens);
            },
            else => return error.SyntaxError,
        }
    };

    return .{ .name = name, .params = params, .block = block };
}
```

There is one big item left, which is `BlockItem`, which can be a function declaration as well as a variable declaration, and it is not possible to know which is which from the token `type_int` as done before.

The most straightforward way to implement it in the current code base is as follows: look for an `type_int` token, verify there is an identifier token afterwards, _without_ recording it, then see what the third token is. If it is a `semicolon` or an `equals`, it is a variable; if it is a prenthesis, it is a function; otherwise it is illegal. Then the parser is rewinded to the `int` and the correct function is called. In later chapters, with global variables, it will be apparent that the only place which only accepts one type of declarations is the `for` loop statement, but I will cross that bridge when I get to it.

```zig
fn parse_decl(
    arena: std.mem.Allocator,
    tokens: *lexer.Tokenizer,
) Error!ast.Decl {
    const int_token = tokens.next() orelse
        return error.NotEnoughJunk;
    if (int_token.tag != .type_int) return error.SyntaxError;
    _ = try expect(.identifier, tokens);

    const new_token = tokens.next() orelse
        return error.NotEnoughJunk;

    tokens.put_back(int_token);
    switch (new_token.tag) {
        .semicolon, .equals => return .{ .V = try parse_var_decl(arena, tokens) },
        .l_paren => return .{ .F = try parse_func_decl(arena, tokens) },
        else => return error.SyntaxError,
    }
}
```

Parsing function calls is a new challenge. Previously, any identifier is immediately assumed to be a variable. But nowm if the identifier is followe by parenthesis, it could be a function call with an arbitrary number of parameters. The new `identifier` case exhibits a serious case of rightward drift.

```zig
.identifier => {
    const next_token = tokens.next() orelse
        return error.NotEnoughJunk;
    const name = tokens.buffer[current.loc.start..current.loc.end];

    switch (next_token.tag) {
        .l_paren => return .{ .func_call = .{
            .{ .name = name },
            try parse_args(arena, tokens),
        } },
        else => {
            tokens.put_back(next_token);
            return .{ .@"var" = .{ .name = name } };
        },
    }
},

// elsewhere:
fn parse_args(
    arena: std.mem.Allocator,
    tokens: *lexer.Tokenizer,
) Error!std.SegmentedList(ast.Expr, 0) {
    // assumes l_paren already consumed
    var ret: std.SegmentedList(ast.Expr, 0) = .{};

    const current = tokens.next() orelse
        return error.NotEnoughJunk;

    args: switch (current.tag) {
        .r_paren => return ret,
        .comma => {
            const expr = try parse_expr(arena, tokens, 0);
            try ret.append(arena, expr);

            const n_token = tokens.next() orelse
                return error.NotEnoughJunk;
            continue :args n_token.tag;
        },
        else => { // only actually relevant for the first argument.
            tokens.put_back(current);
            continue :args .comma;
        },
    }
}
```
