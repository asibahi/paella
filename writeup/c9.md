# Writing a C Compiler - Chapter 9 - in Zig

<!-- Done Date: 2025-05-27 -->

After [eight](c8.md) grueling (not really) chapters of [Writing a C Compiler](https://norasandler.com/2022/03/29/Write-a-C-Compiler-the-Book.html), time to implement more assembly instructions. Functions! Linkage! Commas!

---

## Lexer, AST, and Parser

Lexer just has a comma now. I thought about adding the comma operator but that didnt seem worth the trouble.

The AST has two new additions. Function call expressions and function declarations (which are rebranded and improved function definitons)! Other changes include how the structures themselves are defined. A program is now a _list_ of function delcarations, instead of just one. How about that?

These are the new AST nodes. I am not sure these compile or not yet, which I will find out when I am done with the parser. The use of `SegmentedList` is discussed a couple of chapters ago as a more Arena-friendly collection type.

```zig
pub const Prgm = struct {
    funcs: std.SegmentedList(FuncDecl, 0),
};

pub const Block = struct {
    body: std.SegmentedList(BlockItem, 0),
};

pub const BlockItem = union(enum) {
    D: Decl,
    S: Stmt,
};

pub const Decl = union(enum) {
    F: FuncDecl,
    V: VarDecl,
};

pub const FuncDecl = struct {
    name: []const u8,
    params: std.SegmentedList(Identifier, 0),
    block: ?Block,
};

pub const VarDecl = struct {
    name: Identifier,
    init: ?*Expr,
};

pub const Expr = union(enum) {
    // snip --
    func_call: struct { Identifier, std.SegmentedList(Expr, 0) },
};

// This was implemented last chapter fixing the Segmentation Fault!
pub const Identifier = union(enum) {
    name: []const u8,
    idx: utils.StringInterner.Idx,
};
```

It is going to be annoying fixing all the type errors throughout. Nonethelesss the parsing grammar for these new node types are going to change significantly. Here is. This is the new, tentative, `parse_prgm`. I am not sure this is entirely correct yet.

```zig
pub fn parse_prgm(
    arena: std.mem.Allocator,
    tokens: *lexer.Tokenizer,
) Error!ast.Prgm {
    var funcs: std.SegmentedList(ast.FuncDecl, 0) = .{};

    while (tokens.next()) |next_token| {
        tokens.put_back(next_token);
        const func_decl = try parse_func_decl(arena, tokens);
        try funcs.append(arena, func_decl);
    }

    return .{ .funcs = funcs };
}
```

`parse_func_decl` is the same as the old `parse_func_def`, but with optional parameters and an optional body. Ok maybe not the same, it is a behemoth. And all this is going to get siginficantly more complex when adding different types than `int`.

```zig
fn parse_func_decl(
    arena: std.mem.Allocator,
    tokens: *lexer.Tokenizer,
) Error!ast.FuncDecl {
    // same old
    try expect(.type_int, tokens);
    const name = try expect(.identifier, tokens);

    // new stuff !!
    var params: std.SegmentedList(ast.Identifier, 0) = .{};
    { // params
        try expect(.l_paren, tokens);
        const next_token = tokens.next() orelse
            return error.SyntaxError;
        // labelled switch to loop over mutliple parameters.
        params: switch (next_token.tag) {
            // old bahaviour is this:
            .keyword_void => try expect(.r_paren, tokens),

            // new optional parameters
            .type_int => {
                const ident = try expect(.identifier, tokens);
                try params.append(arena, .{ .name = ident });
                const next_next = tokens.next() orelse
                    return error.SyntaxError;

                // loops back here. this would be sginifcantly more annoying
                // to write without labeled switch
                switch (next_next.tag) {
                    .comma => {
                        try expect(.type_int, tokens);
                        continue :params .type_int;
                    },
                    .r_paren => {},

                    // could just retunr here but where is the fun then?
                    else => continue :params .invalid,
                }
            },
            else => return error.SyntaxError,
        }
    }
    const block = block: {
        const peeked = tokens.next() orelse
            return error.SyntaxError;

        switch (peeked.tag) {
            .semicolon => break :block null,
            .l_brace => {
                tokens.put_back(peeked);
                break :block try parse_block(arena, tokens);
            },
            else => return error.SyntaxError,
        }
    };

    return .{ .name = name, .params = params, .block = block };
}
```

There is one big item left, which is `BlockItem`, which can be a function declaration as well as a variable declaration, and it is not possible to know which is which from the token `type_int` as done before.

The most straightforward way to implement it in the current code base is as follows: look for an `type_int` token, verify there is an identifier token afterwards, _without_ recording it, then see what the third token is. If it is a `semicolon` or an `equals`, it is a variable; if it is a prenthesis, it is a function; otherwise it is illegal. Then the parser is rewinded to the `int` and the correct function is called. In later chapters, with global variables, it will be apparent that the only place which only accepts one type of declarations is the `for` loop statement, but I will cross that bridge when I get to it.

```zig
fn parse_decl(
    arena: std.mem.Allocator,
    tokens: *lexer.Tokenizer,
) Error!ast.Decl {
    const int_token = tokens.next() orelse
        return error.NotEnoughJunk;
    if (int_token.tag != .type_int) return error.SyntaxError;
    _ = try expect(.identifier, tokens);

    const new_token = tokens.next() orelse
        return error.NotEnoughJunk;

    tokens.put_back(int_token);
    switch (new_token.tag) {
        .semicolon, .equals => return .{ .V = try parse_var_decl(arena, tokens) },
        .l_paren => return .{ .F = try parse_func_decl(arena, tokens) },
        else => return error.SyntaxError,
    }
}
```

Parsing function calls is a new challenge. Previously, any identifier is immediately assumed to be a variable. But nowm if the identifier is followe by parenthesis, it could be a function call with an arbitrary number of parameters. The new `identifier` case exhibits a serious case of rightward drift.

```zig
.identifier => {
    const next_token = tokens.next() orelse
        return error.NotEnoughJunk;
    const name = tokens.buffer[current.loc.start..current.loc.end];

    switch (next_token.tag) {
        .l_paren => return .{ .func_call = .{
            .{ .name = name },
            try parse_args(arena, tokens),
        } },
        else => {
            tokens.put_back(next_token);
            return .{ .@"var" = .{ .name = name } };
        },
    }
},

// elsewhere:
fn parse_args(
    arena: std.mem.Allocator,
    tokens: *lexer.Tokenizer,
) Error!std.SegmentedList(ast.Expr, 0) {
    // assumes l_paren already consumed
    var ret: std.SegmentedList(ast.Expr, 0) = .{};

    const current = tokens.next() orelse
        return error.NotEnoughJunk;

    args: switch (current.tag) {
        .r_paren => return ret,
        .comma => {
            const expr = try parse_expr(arena, tokens, 0);
            try ret.append(arena, expr);

            const n_token = tokens.next() orelse
                return error.NotEnoughJunk;
            continue :args n_token.tag;
        },
        else => { // only actually relevant for the first argument.
            tokens.put_back(current);
            continue :args .comma;
        },
    }
}
```

## Semantic Analysis

This is a biit moe involved than usual this chapter. In addition to variable resolution, the compiler needs to do type checking! Do all declarations of functions (which _can_ repeat), have the same number of parameters?

Starting with the easier stuff, the identifier resolution pass should handle the new function syntax. Start with function calls. Here is the added part in `resolve_expr`.

```zig
.func_call => |*f| {
    if (bp.variable_map.get(f.@"0".name)) |entry| {
        f.@"0" = .{ .idx = entry.name };
        var iter = f.@"1".iterator(0);
        while (iter.next()) |item|
            try resolve_expr(bp, item);
    } else return error.Undeclaredfunction;
},
```

Resolving function declarations had me move the creation of the main variable map back into `resolve_prgm` instead, and create a new inner map for every function. Also, I need to update the `Entry` type of the variable map. This is the new `Entry`.

```zig
const Entry = struct {
    name: utils.StringInterner.Idx,
    scope: enum { local, parent } = .local,
    linkage: enum { none, external } = .none, // <-- new
};
```

Then this is `resolve_func_decl`, and the inner parameters resolution, which is really just a cheap copy of `resolve_var_decl` itself rebranded `resolve_decl`.

```zig
fn resolve_func_decl(
    bp: Boilerplate,
    func_decl: *ast.FuncDecl,
) Error!void {
    if (bp.variable_map.get(func_decl.name)) |prev|
        if (prev.scope == .local and prev.linkage != .external)
            return error.DuplicateFunctionDecl;

    try bp.variable_map.put(bp.gpa, func_decl.name, .{
        .name = try bp.strings.get_or_put(bp.gpa, func_decl.name),
        .scope = .local,
        .linkage = .external,
    });

    var variable_map = try bp.variable_map.clone(bp.gpa);
    defer variable_map.deinit(bp.gpa);

    var iter = variable_map.valueIterator();
    while (iter.next()) |value|
        value.* = .{
            .name = value.name,
            .scope = .parent,
            .linkage = value.linkage,
        };

    const inner_bp = bp.into_ineer(&variable_map);

    var iter = func_decl.params.iterator(0);
    while (iter.next()) |param| {
        // a cheap imitation of `resolve_var_decl`
        // should pribably be in its own function.
        if (inner_bp.variable_map.get(param.name)) |entry|
            if (entry.scope == .local)
                return error.DuplicateVariableDecl;

        const unique_name = try inner_bp.make_temporary(param.name);
        try inner_bp.variable_map.put(inner_bp.gpa, param.name, .{ .name = unique_name });

        param.* = .{ .idx = unique_name };
    }

    if (func_decl.block) |*block|
        try resolve_block(inner_bp, null, block);
}
```

One more thing, there is need to check that block level function declarations have no body. I am going to do that in `resolve_block`.

```zig
fn resolve_block(
    bp: Boilerplate,
    current_label: ?utils.StringInterner.Idx,
    block: *ast.Block,
) Error!void {
    var iter = block.body.iterator(0);
    while (iter.next()) |item| switch (item.*) {
        .S => |*s| try resolve_stmt(bp, current_label, s),
        .D => |*d| switch (d.*) {
            .F => |*f| if (f.block) |_|
                return error.IllegalFuncDefinition
            else
                try resolve_func_decl(bp, f),
            .V => |*v| try resolve_var_decl(bp, v),
        },
    };
}
```

Before delving into type checking, the book suggests to run the test suite, but expect a number of failures. Thankfully, I can check the individual folders separately using the eye test, without running the test suite in the official manner, I can tell that the compiler is passing all the right files it should at this stage, even the ones in `invalid_types`.

## Type checking

The Book has the type checking done in its own pass. At first, I tried just stuffing the type checking logic right into the same identifier resolution pass. But the actual problem was that I needed a separate data structure anyway, since function declarations have to match even when they are in different scopes. So I am still doing it in the same run, but with a separate data structure.

The type checking consists mostly of the following: not using the same identifier for both `int`s and functions, making sure functions always have the same number of parameters in all declarations, and make sure a function is not defined (with a body) twice.

A new data structure would be needed to stuff this info, global throughout the whole file.[^linker] A hashmap taking the unique identifiers as keys and their types as values. The type is either an integer or a function with defined arity (number of parameters). I also need to track whether a function has been defined or not.

[^linker]: Type errors between different files is very pointedly a not-my-problem. It is a linker error, while this is a compiler.

```zig
const TypeMap = std.AutoHashMapUnmanaged(
    u32,
    Type,
);

const Type = union(enum) {
    int,
    func: struct {
        arity: usize,
        defined: bool,
    },
};
```

Then adding a pointer to it to `Boilerplate`, and adjusting `resolve_prgm` as follows.

```zig
pub fn resolve_prgm(
    gpa: std.mem.Allocator,
    strings: *utils.StringInterner,
    prgm: *ast.Prgm,
) Error!void {
    var variable_map: VariableMap = .empty;
    defer variable_map.deinit(gpa);

    var type_map: TypeMap = .empty;
    defer type_map.deinit(gpa);

    const bp: Boilerplate = .{
        .gpa = gpa,
        .strings = strings,
        .variable_map = &variable_map,
        .type_map = &type_map,
    };

    var iter = prgm.funcs.iterator(0);
    while (iter.next()) |item|
        try resolve_func_decl(bp, item);
}
```

What follows next is lots of annoying boilerplate. I must make sure every time I add something to a `variable_map`, I am adding its new name (if any) to `type_map`. Hairier than usual logic, but should try to straighten it out before stuffing it in a `Boilerplate` method.

For example, in `resolve_finc_decl`, adding a name to `variable_map` and `type_map` is done as follows:

```zig
{
    const nname = try bp.strings.get_or_put(bp.gpa, func_decl.name);
    try bp.variable_map.put(bp.gpa, func_decl.name, .{
        .name = nname,
        .scope = .local,
        .linkage = .external,
    });
    const gop = try bp.type_map.getOrPut(bp.gpa, nname.real_idx);
    if (gop.found_existing) {
        if (gop.value_ptr.* != .func or
            gop.value_ptr.func.arity != func_decl.params.count())
        {
            return error.TypeError;
        } else if (gop.value_ptr.func.defined and
            func_decl.block != null)
        {
            return error.DuplicateFunctionDef;
        }
    } else gop.value_ptr.* = .{ .func = .{
        .arity = func_decl.params.count(),
        .defined = func_decl.block != null,
    } };
}
```

A similar thing to do in `resolve_var_decl`, and inside the small tidbit in `resolve_func_decl` that reolves paramters. This is how it looks like.

```zig
{
    const gop = try bp.type_map.getOrPut(bp.gpa, unique_name.real_idx);
    if (gop.found_existing) {
        if (gop.value_ptr.* != .int) {
            return error.TypeError;
        }
    } else gop.value_ptr.* = .int;
}
```

There does not seem enough shared logic right now to try and DRY these. Maybe later. What is left is checking these things in function calls and variable declarations. They are both very funny looking.

```zig
.@"var" => |name| {
    if (bp.variable_map.get(name.name)) |un| {
        if (bp.type_map.get(un.name.real_idx).? == .int) // unwrap optional
            expr.* = .{ .@"var" = .{ .idx = un.name } }
        else
            return error.TypeError;
    } else return error.UndeclaredVariable;
},
.func_call => |*f| {
    if (bp.variable_map.get(f.@"0".name)) |entry| {
        const t = bp.type_map.get(entry.name.real_idx).?;
        if (t == .func and
            t.func.arity == f.@"1".count())
        {
            f.@"0" = .{ .idx = entry.name };
            var iter = f.@"1".iterator(0);
            while (iter.next()) |item|
                try resolve_expr(bp, item);
        } else return error.TypeError;
    } else return error.UndeclaredFunction;
},
```

I 8think\* this should be it. I checked for functions being defined twice/ I checked that functions should be functions and types should be types. I checked all functions with the same name should have the same arity. `zig build` returns no errors. What is left?

The proof of the pudding is in the test suite. Time to run the test suite. (which now applies `--latest-only` by default as not to take _too_ long.)

```sh
% paella ❱ zig build submit -- --chapter 9 --stage validate
----------------------------------------------------------------------
Ran 61 tests in 157.089s

OK
```

_Phew_. Mind you this does not mean the logic is correct. It just means it is failing the ones it should fail and passing the ones it should pass. The full test suite passes as well, which is cool.
