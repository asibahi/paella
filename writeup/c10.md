# Writing a C Compiler - Chapter 10 - in Zig

<!-- Done Date: 2025-06-01 -->

This is the final chapter of Part 1 of [Writing a C Compiler](https://norasandler.com/2022/03/29/Write-a-C-Compiler-the-Book.html). Something about static variables?

---

## Lexer

The Book spends 15 pages talking about linkage and static variabeles and tentative declarations, etc, before it gets to the lexer. Only two new keywrods are needed: `static` and `extern`. This is the current keyword static map:

```zig
pub const keywords = std.StaticStringMap(Tag).initComptime(.{
    .{ "int", .type_int },

    .{ "return", .keyword_return },
    .{ "void", .keyword_void },

    .{ "if", .keyword_if },
    .{ "else", .keyword_else },

    .{ "do", .keyword_do },
    .{ "while", .keyword_while },
    .{ "for", .keyword_for },
    .{ "break", .keyword_break },
    .{ "continue", .keyword_continue },

    .{ "static", .keyword_static },
    .{ "extern", .keyword_extern },
});
```

As a small update to the lexer's API, I added a `next_force` function that returns an error union rather than an option, as it is easier to deal with at the call site.

```zig
pub inline fn next_force(self: *Tokenizer) !Token {
    return self.next() orelse
        return error.NotEnoughJunk;
}

// usage
var token = try tokens.next_force();
// rather than
var token = tokens.next() orlse return error.NotEnoughJunk;
```

## AST and Parser

The parser requires deeper changes. First of all, as `Prgm` changed from a single function to multiple functions last chapter, now it is a list of _declarations_. Also, `static` and `extern` belong, by themselves, to a new semi-node for "storage class specifiers", that is an optional parameter for function and variable declarations. Since a declaration cannot be both `static` _and_ `extern`, this makes it a simple enum.

```zig
pub const Prgm = struct {
    funcs: std.SegmentedList(Decl, 0),
};

pub const StorageClass = enum { static, @"extern" };

pub const FuncDecl = struct {
    sc: ?StorageClass, // <--
    name: []const u8,
    params: std.SegmentedList(Identifier, 0),
    block: ?Block,
};

pub const VarDecl = struct {
    sc: ?StorageClass, // <--
    name: Identifier,
    init: ?*Expr,
}
```

Changes to `parse_prgm` are simple enough. There already is a `parse_decl` so I will just use that one when iterating. Parsing specifiers is interesting and annoying, as I relied before on looking for the `int` token, now it can be anything! Consider these tqo equally valid variable declarations.

```c
static int example1 = 1;

int static example2 = 2;
```

There is no set order. Whose genius idea was this? Thankfully I do not have to think of this on my own, as the book privdes a nice pseudocode functon to parse them. When I was doing my Rust implementation, where I was using `nom` for parsing, I could not actually figure out to make it nicer than what the Book already provided. Here is the function translated from pseudo code to Zig.[^types]

[^types]: The Book's function is more complicated that is needed right now but is written this way to accomodate different types in Part 2. As I am not planning to implement Part 2 this run, there is need for the `parse_type` half.

```zig
fn parse_storage_class(
    tokens: *lexer.Tokenizer,
) Error!?ast.StorageClass {
    var type_seen = false;
    var sc: ?ast.StorageClass = null;

    while (tokens.next()) |nt| switch (nt.tag) {
        .type_int => type_seen = true,
        .keyword_static => sc = if (sc == null)
            .static
        else
            return error.InvalidStorageClass,
        .keyword_extern => sc = if (sc == null)
            .@"extern"
        else
            return error.InvalidStorageClass,
        else => {
            tokens.put_back(nt);
            break;
        },
    } else return error.NotEnoughJunk;

    if (!type_seen) return error.InvalidTypeSpecifier;
    return sc;
}
```

Then use this new function in both `parse_func_decl` and `parse_variable_decl`. In fact, it is probably easier right now to just simply unify the two into a horrendous giant amalgamation.

```zig

fn parse_decl(
    arena: std.mem.Allocator,
    tokens: *lexer.Tokenizer,
    ty: union(enum) { @"var": ?ast.StorageClass, either },
) Error!ast.Decl {
    const sc = if (ty == .@"var") ty.@"var" else try parse_storage_class(tokens);
    const name = try expect(.identifier, tokens);

    const new_token = try tokens.next_force();

    switch (new_token.tag) {
        .semicolon => return .{ .V = .{
            .sc = sc,
            .name = .{ .name = name },
            .init = null,
        } },
        .equals => {
            const expr = try parse_expr(arena, tokens, 0);
            const expr_ptr = try utils.create(arena, expr);

            try expect(.semicolon, tokens);
            return .{ .V = .{
                .sc = sc,
                .name = .{ .name = name },
                .init = expr_ptr,
            } };
        },
        .l_paren => {
            if (ty == .@"var") return error.SyntaxError;
            var params: std.SegmentedList(ast.Identifier, 0) = .{};

            const param_peek = try tokens.next_force();
            params: switch (param_peek.tag) {
                .keyword_void => try expect(.r_paren, tokens),
                .type_int => {
                    const ident = try expect(.identifier, tokens);
                    try params.append(arena, .{ .name = ident });
                    const inner_param_peek = try tokens.next_force();
                    switch (inner_param_peek.tag) {
                        .comma => {
                            try expect(.type_int, tokens);
                            continue :params .type_int;
                        },
                        .r_paren => {},
                        else => continue :params .invalid,
                    }
                },
                else => return error.SyntaxError,
            }

            const block_peek = try tokens.next_force();
            const block = block: {
                switch (block_peek.tag) {
                    .semicolon => break :block null,
                    .l_brace => {
                        tokens.put_back(block_peek);
                        break :block try parse_block(arena, tokens);
                    },
                    else => return error.SyntaxError,
                }
            };

            return .{ .F = .{
                .sc = sc,
                .name = name,
                .params = params,
                .block = block,
            } };
        },
        else => return error.SyntaxError,
    }
}
```

The `ty` parameter is because there is one place in the AST that _requires_ a variable declaration specifically, which is the initial part of a `for` loop. (It is not `comptime` because I use to sneak in an already parsed `sc` value, as you will see.) Everywhere else can really take either declaration type.

This is the part in `for` loop parsing that deals with the new parsing functions.

```zig
const init: ast.Stmt.For.Init = init: {
    const peeked = try tokens.next_force();
    if (peeked.tag == .semicolon) break :init .none else {
        tokens.put_back(peeked);
        if (parse_storage_class(tokens)) |sc| {
            const decl = try parse_decl(
                arena,
                tokens,
                .{ .@"var" = sc }, // <-- snuck in
            );
            const decl_ptr = try utils.create(arena, decl.V); // <-- unwrapped
            break :init .{ .decl = decl_ptr };
        } else |_| { // <-- parse_sc already puts back any other token
            const expr = try parse_expr(arena, tokens, 0);
            const expr_ptr = try utils.create(arena, expr);
            try expect(.semicolon, tokens);
            break :init .{ .expr = expr_ptr };
        }
    }
};
```

Running the eye test I quickly ran into a bug. *Sigh.

## Debugging the Parser
