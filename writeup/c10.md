# Writing a C Compiler - Chapter 10 - in Zig

<!-- Done Date: 2025-06-01 -->

This is the final chapter of Part 1 of [Writing a C Compiler](https://norasandler.com/2022/03/29/Write-a-C-Compiler-the-Book.html). Something about static variables?

---

## Lexer

The Book spends 15 pages talking about linkage and static variabeles and tentative declarations, etc, before it gets to the lexer. Only two new keywrods are needed: `static` and `extern`. This is the current keyword static map:

```zig
pub const keywords = std.StaticStringMap(Tag).initComptime(.{
    .{ "int", .type_int },

    .{ "return", .keyword_return },
    .{ "void", .keyword_void },

    .{ "if", .keyword_if },
    .{ "else", .keyword_else },

    .{ "do", .keyword_do },
    .{ "while", .keyword_while },
    .{ "for", .keyword_for },
    .{ "break", .keyword_break },
    .{ "continue", .keyword_continue },

    .{ "static", .keyword_static },
    .{ "extern", .keyword_extern },
});
```

As a small update to the lexer's API, I added a `next_force` function that returns an error union rather than an option, as it is easier to deal with at the call site.

```zig
pub inline fn next_force(self: *Tokenizer) !Token {
    return self.next() orelse
        return error.NotEnoughJunk;
}

// usage
var token = try tokens.next_force();
// rather than
var token = tokens.next() orlse return error.NotEnoughJunk;
```

## AST and Parser

The parser requires deeper changes. First of all, as `Prgm` changed from a single function to multiple functions last chapter, now it is a list of _declarations_. Also, `static` and `extern` belong, by themselves, to a new semi-node for "storage class specifiers", that is an optional parameter for function and variable declarations. Since a declaration cannot be both `static` _and_ `extern`, this makes it a simple enum.

```zig
pub const Prgm = struct {
    funcs: std.SegmentedList(Decl, 0),
};

pub const StorageClass = enum { static, @"extern" };

pub const FuncDecl = struct {
    sc: ?StorageClass, // <--
    name: []const u8,
    params: std.SegmentedList(Identifier, 0),
    block: ?Block,
};

pub const VarDecl = struct {
    sc: ?StorageClass, // <--
    name: Identifier,
    init: ?*Expr,
}
```

Changes to `parse_prgm` are simple enough. There already is a `parse_decl` so I will just use that one when iterating. Parsing specifiers is interesting and annoying, as I relied before on looking for the `int` token, now it can be anything! Consider these tqo equally valid variable declarations.

```c
static int example1 = 1;

int static example2 = 2;
```

There is no set order. Whose genius idea was this? Thankfully I do not have to think of this on my own, as the book privdes a nice pseudocode functon to parse them. When I was doing my Rust implementation, where I was using `nom` for parsing, I could not actually figure out to make it nicer than what the Book already provided. Here is the function translated from pseudo code to Zig.[^types]

[^types]: The Book's function is more complicated that is needed right now but is written this way to accomodate different types in Part 2. As I am not planning to implement Part 2 this run, there is need for the `parse_type` half.

```zig
fn parse_storage_class(
    tokens: *lexer.Tokenizer,
) Error!?ast.StorageClass {
    var type_seen = false;
    var sc: ?ast.StorageClass = null;

    while (tokens.next()) |nt| switch (nt.tag) {
        .type_int => type_seen = true,
        .keyword_static => sc = if (sc == null)
            .static
        else
            return error.InvalidStorageClass,
        .keyword_extern => sc = if (sc == null)
            .@"extern"
        else
            return error.InvalidStorageClass,
        else => {
            tokens.put_back(nt);
            break;
        },
    } else return error.NotEnoughJunk;

    if (!type_seen) return error.InvalidTypeSpecifier;
    return sc;
}
```

Then use this new function in both `parse_func_decl` and `parse_variable_decl`. In fact, it is probably easier right now to just simply unify the two into a horrendous giant amalgamation.

```zig

fn parse_decl(
    arena: std.mem.Allocator,
    tokens: *lexer.Tokenizer,
    ty: union(enum) { @"var": ?ast.StorageClass, either },
) Error!ast.Decl {
    const sc = if (ty == .@"var") ty.@"var" else try parse_storage_class(tokens);
    const name = try expect(.identifier, tokens);

    const new_token = try tokens.next_force();

    switch (new_token.tag) {
        .semicolon => return .{ .V = .{
            .sc = sc,
            .name = .{ .name = name },
            .init = null,
        } },
        .equals => {
            const expr = try parse_expr(arena, tokens, 0);
            const expr_ptr = try utils.create(arena, expr);

            try expect(.semicolon, tokens);
            return .{ .V = .{
                .sc = sc,
                .name = .{ .name = name },
                .init = expr_ptr,
            } };
        },
        .l_paren => {
            if (ty == .@"var") return error.SyntaxError;
            var params: std.SegmentedList(ast.Identifier, 0) = .{};

            const param_peek = try tokens.next_force();
            params: switch (param_peek.tag) {
                .keyword_void => try expect(.r_paren, tokens),
                .type_int => {
                    const ident = try expect(.identifier, tokens);
                    try params.append(arena, .{ .name = ident });
                    const inner_param_peek = try tokens.next_force();
                    switch (inner_param_peek.tag) {
                        .comma => {
                            try expect(.type_int, tokens);
                            continue :params .type_int;
                        },
                        .r_paren => {},
                        else => continue :params .invalid,
                    }
                },
                else => return error.SyntaxError,
            }

            const block_peek = try tokens.next_force();
            const block = block: {
                switch (block_peek.tag) {
                    .semicolon => break :block null,
                    .l_brace => {
                        tokens.put_back(block_peek);
                        break :block try parse_block(arena, tokens);
                    },
                    else => return error.SyntaxError,
                }
            };

            return .{ .F = .{
                .sc = sc,
                .name = name,
                .params = params,
                .block = block,
            } };
        },
        else => return error.SyntaxError,
    }
}
```

The `ty` parameter is because there is one place in the AST that _requires_ a variable declaration specifically, which is the initial part of a `for` loop. (It is not `comptime` because I use to sneak in an already parsed `sc` value, as you will see.) Everywhere else can really take either declaration type.

This is the part in `for` loop parsing that deals with the new parsing functions.

```zig
const init: ast.Stmt.For.Init = init: {
    const peeked = try tokens.next_force();
    if (peeked.tag == .semicolon) break :init .none else {
        tokens.put_back(peeked);
        if (parse_storage_class(tokens)) |sc| {
            const decl = try parse_decl(
                arena,
                tokens,
                .{ .@"var" = sc }, // <-- snuck in
            );
            const decl_ptr = try utils.create(arena, decl.V); // <-- unwrapped
            break :init .{ .decl = decl_ptr };
        } else |_| { // <-- parse_sc already puts back any other token
            const expr = try parse_expr(arena, tokens, 0);
            const expr_ptr = try utils.create(arena, expr);
            try expect(.semicolon, tokens);
            break :init .{ .expr = expr_ptr };
        }
    }
};
```

Running the eye test I quickly ran into a bug. \*Sigh.

## Debugging the Parser

It failed on the first test, so obviously this is a bug in the general algorithm. With all the new changes all at once it is ahrder to pinpoint which one it is. I did not make a separate commit for every refactor, I am afraid. This is the C file it failed on (after removing comments).

```c
int putchar (int ch);

int print_letters(void) {
    static int i = 65;
    putchar(i);
    {
        i = i + 1;
        static int i = 97;
        putchar(i);
        i = i + 1;
    }
    putchar(10);
    return 0;
}

int main(void) {
    for (int i = 0; i < 26; i = i + 1)
        print_letters();
}
```

Adding debugging printers to `next()` and `put_back()`, as done previously, will let me see where it failed in the file. I could also print the failed token's span, but that would require better architecture and more dedication. I get this stream of consciusness back. I added comments to each line, manually, to be honest, to track which function does which.

```
NEXT   type_int 0-3		# parse_prgm
REWIND type_int 0-3		# parse_prgm
NEXT   type_int 0-3		# parse_decl ->  parse_storage_class
NEXT   identifier 4-11		# parse_storage_class
REWIND identifier 4-11		# parse_storage_class
NEXT   identifier 4-11		# parse_decl
NEXT   l_paren 12-13		# parse_decl
NEXT   type_int 13-16		# parse_decl # params
NEXT   identifier 17-19		# parse_decl # params
NEXT   r_paren 19-20		# parse_decl # params
NEXT   semicolon 20-21		# parse_decl # block
NEXT   type_int 22-25		# parse_prgm
REWIND type_int 22-25		# parse_prgm
NEXT   type_int 22-25		# parse_decl ->  parse_storage_class
NEXT   identifier 26-39		# parse_storage_class
REWIND identifier 26-39		# parse_storage_class
NEXT   identifier 26-39		# parse_decl
NEXT   l_paren 39-40		# parse_decl
NEXT   keyword_void 40-44	# parse_decl # params
NEXT   r_paren 44-45		# parse_decl # params
NEXT   l_brace 46-47		# parse_decl # block
REWIND l_brace 46-47		# parse_decl # block
NEXT   l_brace 46-47		# parse_block
NEXT   keyword_static 52-58	# parse_block
REWIND keyword_static 52-58	# parse_block
NEXT   keyword_static 52-58	# parse_block_item
REWIND keyword_static 52-58	# parse_block_item
NEXT   keyword_static 52-58	# .. oh
REWIND keyword_static 52-58
NEXT   keyword_static 52-58
error: SyntaxError
```

Oh yeah here it is. I forgot to update it and `parse_block_item` still checks for whether something is a declaration or a statement using the `int` keyword. I could use a similar trick to what I did for the `for` loop where I can pass the parsed value in instead of peeking and parsing it again. This would require changes to `parse_decl`s signature, so I will start with that. This is the current signature.

```zig
fn parse_decl(
    arena: std.mem.Allocator,
    tokens: *lexer.Tokenizer,
    ty: union(enum) { @"var": ?ast.StorageClass, either },
) Error!ast.Decl {
    const sc = if (ty == .@"var") ty.@"var" else try parse_storage_class(tokens);
    // etc
```

Instead of smuggling the parsed value through `ty`, I could change `ty` to my earlier iteration of an `enum`, and pass whether it is parsed or not in another variable, like so.

```zig
fn parse_decl(
    comptime ty: enum { @"var", either },
    arena: std.mem.Allocator,
    tokens: *lexer.Tokenizer,
    parsed: union(enum) { yes:?ast.StorageClass, no },
) Error!ast.Decl {
    const sc = if (parsed == .yes) parsed.yes else try parse_storage_class(tokens);
    // etc
```

And changing the call sites, again, but no matter. Here is the new and improved `parse_block_item`, relying on `parse_storage_class` putting back any unrecognized tokens.

```zig
fn parse_block_item(
    arena: std.mem.Allocator,
    tokens: *lexer.Tokenizer,
) Error!ast.BlockItem {
    if (parse_storage_class(tokens)) |sc|
        return .decl(try parse_decl(.either, arena, tokens, .{ .yes = sc }))
    else |_|
        return .stmt(try parse_stmt(arena, tokens));
}
```

And voila! Running the parser on the same C file above renders the following AST (with some updated printing for variable declarations).

```
PROGRAM
	FUNCTION putchar ch
	FUNCTION print_letters
		static VARIABLE i <- 65
		(putchar i);
		DO
			(i <- (+ i 1));
			static VARIABLE i <- 97
			(putchar i);
			(i <- (+ i 1));
		(putchar 10);
		RETURN 0
	FUNCTION main
		FOR VARIABLE i <- 0; (< i 26); (i <- (+ i 1))
			(print_letters);
```

The eye test passes. The actual test suite passes. All is done and all is happy with the tiny world of this project.

---
